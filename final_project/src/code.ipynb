{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Competitive Auctions on eBay.com\n",
    "\n",
    "## eBay.com의 경쟁적인 경매\n",
    "\n",
    "- [eBayAuction.csv] 파일에는 2004년 5~6월에 eBay.com에서 거래된 총 1,972건의 경매 정보가 담겨 있다. 분석 목적은 이 데이터를 사용해 경쟁적인 경매와 비경쟁적인 경매를 구분하는 모델을 구축하는 것이다.\n",
    "\n",
    "- 경쟁적인 경매는 경매되고 있는 물품에 대해 최소한 2개 이상의 입찰이 있는 경매로 정의된다. 데이터는 물품을 나타내는 변수(경매 범주), 판매자 등급(eBay 등급), 판매자가 선택한 경매 조건(경매 기간, 시작가(OpenPrice), 화폐 단위, 경매 마감 요일)을 포함한다. 경매가 마감된 가격(ClosePrice)에 대한 데이터도 있다. 분석 목표는 경매가 경쟁적인지 아닌지를 예측하는 것이다.\n",
    "\n",
    "- 데이터 전처리: 범주형 예측 변수들에 대해서 더미 변수를 생성하시오. 범주형 변수에는 물품 항목(Category: 18개 범주), 화폐 단위(currency: US, GBP, EUR), 경매 종료일(endDay: 월요일~일요일), 경매 기간(Duration: 1, 3, 5, 7, 10일)이 포함된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>currency</th>\n",
       "      <th>sellerRating</th>\n",
       "      <th>Duration</th>\n",
       "      <th>endDay</th>\n",
       "      <th>ClosePrice</th>\n",
       "      <th>OpenPrice</th>\n",
       "      <th>Competitive?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Music/Movie/Game</td>\n",
       "      <td>US</td>\n",
       "      <td>3249</td>\n",
       "      <td>5</td>\n",
       "      <td>Mon</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Music/Movie/Game</td>\n",
       "      <td>US</td>\n",
       "      <td>3249</td>\n",
       "      <td>5</td>\n",
       "      <td>Mon</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Music/Movie/Game</td>\n",
       "      <td>US</td>\n",
       "      <td>3249</td>\n",
       "      <td>5</td>\n",
       "      <td>Mon</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Music/Movie/Game</td>\n",
       "      <td>US</td>\n",
       "      <td>3249</td>\n",
       "      <td>5</td>\n",
       "      <td>Mon</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Music/Movie/Game</td>\n",
       "      <td>US</td>\n",
       "      <td>3249</td>\n",
       "      <td>5</td>\n",
       "      <td>Mon</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1967</th>\n",
       "      <td>Automotive</td>\n",
       "      <td>US</td>\n",
       "      <td>2992</td>\n",
       "      <td>5</td>\n",
       "      <td>Sun</td>\n",
       "      <td>359.95</td>\n",
       "      <td>359.95</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1968</th>\n",
       "      <td>Automotive</td>\n",
       "      <td>US</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>Sat</td>\n",
       "      <td>610.00</td>\n",
       "      <td>300.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1969</th>\n",
       "      <td>Automotive</td>\n",
       "      <td>US</td>\n",
       "      <td>1400</td>\n",
       "      <td>5</td>\n",
       "      <td>Mon</td>\n",
       "      <td>549.00</td>\n",
       "      <td>549.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970</th>\n",
       "      <td>Automotive</td>\n",
       "      <td>US</td>\n",
       "      <td>57</td>\n",
       "      <td>7</td>\n",
       "      <td>Fri</td>\n",
       "      <td>820.00</td>\n",
       "      <td>650.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <td>Automotive</td>\n",
       "      <td>US</td>\n",
       "      <td>145</td>\n",
       "      <td>7</td>\n",
       "      <td>Sat</td>\n",
       "      <td>999.00</td>\n",
       "      <td>999.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1972 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Category currency  sellerRating  Duration endDay  ClosePrice  \\\n",
       "0     Music/Movie/Game       US          3249         5    Mon        0.01   \n",
       "1     Music/Movie/Game       US          3249         5    Mon        0.01   \n",
       "2     Music/Movie/Game       US          3249         5    Mon        0.01   \n",
       "3     Music/Movie/Game       US          3249         5    Mon        0.01   \n",
       "4     Music/Movie/Game       US          3249         5    Mon        0.01   \n",
       "...                ...      ...           ...       ...    ...         ...   \n",
       "1967        Automotive       US          2992         5    Sun      359.95   \n",
       "1968        Automotive       US            21         5    Sat      610.00   \n",
       "1969        Automotive       US          1400         5    Mon      549.00   \n",
       "1970        Automotive       US            57         7    Fri      820.00   \n",
       "1971        Automotive       US           145         7    Sat      999.00   \n",
       "\n",
       "      OpenPrice  Competitive?  \n",
       "0          0.01             0  \n",
       "1          0.01             0  \n",
       "2          0.01             0  \n",
       "3          0.01             0  \n",
       "4          0.01             0  \n",
       "...         ...           ...  \n",
       "1967     359.95             0  \n",
       "1968     300.00             1  \n",
       "1969     549.00             0  \n",
       "1970     650.00             1  \n",
       "1971     999.00             0  \n",
       "\n",
       "[1972 rows x 8 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "eBayAuctions.csv파일을 읽어 DataFrame 생성\n",
    "'''\n",
    "import pandas as pd\n",
    "\n",
    "eBayAuctions_df = pd.read_csv('../data/eBayAuctions.csv')\n",
    "eBayAuctions_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 히스토그램 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no display found. Using non-interactive Agg backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1650233/3698312791.py:34: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_xticklabels(set(extracted_df[col]), rotation=45, ha='right')\n",
      "/tmp/ipykernel_1650233/3698312791.py:37: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
      "  ax.set_xticklabels(['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'])\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import dmba\n",
    "import numpy as np\n",
    "\n",
    "num_col = 3\n",
    "num_row = 3\n",
    "fig = plt.figure(figsize=(15, 15))\n",
    "gs = GridSpec(num_col, num_row, figure=fig)\n",
    "\n",
    "fig.suptitle(\"Histogram of Variables\", fontsize=20)\n",
    "\n",
    "bins_dict = {}\n",
    "for idx, col in enumerate(eBayAuctions_df.columns):\n",
    "\n",
    "    ax = fig.add_subplot(gs[idx//num_col, idx%num_row])\n",
    "    ax.set_title(f\"{col}\")\n",
    "        \n",
    "    if col in ['sellerRating', 'ClosePrice', 'OpenPrice']:  # 분포가 큰 columns\n",
    "        bins = 20\n",
    "        q1 = eBayAuctions_df[col].quantile(0.1) # 하위 10% 값\n",
    "        q3 = eBayAuctions_df[col].quantile(0.9) # 상위 90% 값\n",
    "        extracted_df = eBayAuctions_df[(eBayAuctions_df[col] >= q1) & (eBayAuctions_df[col] <= q3)] # 10~90%만 추출\n",
    "\n",
    "    else:  # 분포가 작은 columns\n",
    "        bins = len(set(eBayAuctions_df[col]))\n",
    "        extracted_df = eBayAuctions_df\n",
    "\n",
    "    counts, bins, patches = ax.hist(extracted_df[col].dropna(), bins=bins)\n",
    "    bins_dict[col] = bins\n",
    "\n",
    "    # x축 라벨 형식 변경\n",
    "    if col in ['Category']:\n",
    "        ax.set_xticklabels(set(extracted_df[col]), rotation=45, ha='right')\n",
    "\n",
    "    elif col in ['endDay']:\n",
    "        ax.set_xticklabels(['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun'])\n",
    "\n",
    "    for count, patch in zip(counts, patches):   # 각 bin의 count 수 표시\n",
    "        x = patch.get_x() + patch.get_width() / 2\n",
    "        y = count\n",
    "        ax.text(x, y, f\"{int(count)}\", ha='center', va='bottom', fontsize=10, color='black')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 변수 별 각 카테고리의 평균 라벨 수치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1650233/235711962.py:25: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  groupAverage = temp_df.groupby([group])[outcome].mean()\n",
      "/tmp/ipykernel_1650233/235711962.py:25: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  groupAverage = temp_df.groupby([group])[outcome].mean()\n",
      "/tmp/ipykernel_1650233/235711962.py:25: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  groupAverage = temp_df.groupby([group])[outcome].mean()\n"
     ]
    }
   ],
   "source": [
    "outcome = 'Competitive?'\n",
    "\n",
    "def createGraph(group, col, row):\n",
    "    groupAverage = eBayAuctions_df.groupby([group])[outcome].mean()\n",
    "    if group == 'endDay': # rotate so that display starts on Sunday\n",
    "        groupAverage = groupAverage.reindex(index=np.roll(groupAverage.index,1))\n",
    "        groupAverage.index = ['Sun', 'Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat']\n",
    "\n",
    "    ax = fig.add_subplot(gs[col, row])\n",
    "    groupAverage.plot.bar(color='C0', ax=ax)\n",
    "    ax.set_title(f\"{group}\")\n",
    "    ax.set_ylabel('Average Competitive')\n",
    "    if group == 'Category':\n",
    "        ax.set_xticklabels(groupAverage.index, rotation=45, ha='right')\n",
    "    else:\n",
    "        ax.set_xticklabels(groupAverage.index, rotation=0, ha='right')\n",
    "    return ax\n",
    "\n",
    "def graphNumericalGraph(group, col, row):\n",
    "    q1 = eBayAuctions_df[group].quantile(0.1) # 하위 10% 값\n",
    "    q3 = eBayAuctions_df[group].quantile(0.9) # 상위 90% 값\n",
    "    extracted_df = eBayAuctions_df[(eBayAuctions_df[group] >= q1) & (eBayAuctions_df[group] <= q3)] # 10~90%만 추출\n",
    "    temp_df = pd.DataFrame({group:  pd.cut(extracted_df[group], bins=bins_dict[group], include_lowest=True),\n",
    "                            outcome: extracted_df[outcome]})\n",
    "    groupAverage = temp_df.groupby([group])[outcome].mean()\n",
    "\n",
    "    ax = fig.add_subplot(gs[col, row])\n",
    "    groupAverage.plot.bar(color='C0', ax=ax)\n",
    "    ax.set_title(f\"{group}\")\n",
    "    ax.set_ylabel('Average Competitive')\n",
    "    ax.set_xticklabels(groupAverage.index, rotation=45, ha='right')\n",
    "\n",
    "num_col = 3\n",
    "num_row = 3\n",
    "fig = plt.figure(figsize=(15, 15))\n",
    "gs = GridSpec(num_col, num_row, figure=fig)\n",
    "\n",
    "fig.suptitle(\"Average Competitive of Variables\", fontsize=20)\n",
    "\n",
    "createGraph('Category', 0, 0)\n",
    "createGraph('currency', 0, 1)\n",
    "graphNumericalGraph('sellerRating', 0, 2)\n",
    "createGraph('Duration', 1, 0)\n",
    "createGraph('endDay', 1, 1)\n",
    "graphNumericalGraph('ClosePrice', 1, 2)\n",
    "graphNumericalGraph('OpenPrice', 2, 1)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Category : 'Antique/Art/Craft'는 가장 경쟁적인 항목이며, 'Coins/Stamps'는 가장 덜 경쟁적인 항목이다.\n",
    "* currency : 'GBP'는 가장 경쟁적인 통화이며, 'EUR'는 가장 덜 경쟁적인 통화이다.\n",
    "* Duration : '5일'은 가장 경쟁적인 기간이며, '1일'은 가장 덜 경쟁적인 기간이다.\n",
    "* endDay   : 'Mon'는 가장 경쟁적인 마감일이며, 'Wed'는 가장 덜 경쟁적인 마감일이다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "- 다양한 범주형 변수들(더미 변수가 아닌 원래 변수 사용)의 함수로서 이진형 결과 변수(경쟁적인 경매 여부)의 평균을 구하기 위해 피벗 테이블을 작성하시오. 모델에서 사용될 더미 변수의 개수를 줄이기 위해서 피벗 테이블의 정보를 활용하시오. 예를 들어, 경쟁적인 경매의 분포가 유사한 범주는 합칠 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Category(카테고리)\n",
    "[eBay.com - Category](https://www.ebay.com/n/all-categories)\n",
    "\n",
    "- Antique/Art/Craft      앤틱/미술/공예   \n",
    "- Automotive             자동차   \n",
    "- Books                  책   \n",
    "- Business/Industrial    비즈니스/산업   \n",
    "- Clothing/Accessories   옷/악세사리   \n",
    "- Coins/Stamps           동전/우표   \n",
    "- Collectibles           수집물   \n",
    "- Computer               컴퓨터   \n",
    "- Electronics            전자기기   \n",
    "- EverythingElse         이외의 것들   \n",
    "- Health/Beauty          헬스/뷰티   \n",
    "- Home/Garden            홈/가든   \n",
    "- Jewelry                쥬얼리   \n",
    "- Music/Movie/Game       음악/영화/게임   \n",
    "- Photography            사진   \n",
    "- Pottery/Glass          도자기/글라스   \n",
    "- SportingGoods          운동용품   \n",
    "- Toys/Hobbies           장난감/취미   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Competitive?\n",
      "Category                          \n",
      "Antique/Art/Craft         0.564972\n",
      "Automotive                0.353933\n",
      "Books                     0.500000\n",
      "Business/Industrial       0.666667\n",
      "Clothing/Accessories      0.504202\n",
      "Coins/Stamps              0.297297\n",
      "Collectibles              0.577406\n",
      "Computer                  0.666667\n",
      "Electronics               0.800000\n",
      "EverythingElse            0.235294\n",
      "Health/Beauty             0.171875\n",
      "Home/Garden               0.656863\n",
      "Jewelry                   0.365854\n",
      "Music/Movie/Game          0.602978\n",
      "Photography               0.846154\n",
      "Pottery/Glass             0.350000\n",
      "SportingGoods             0.725806\n",
      "Toys/Hobbies              0.529915\n"
     ]
    }
   ],
   "source": [
    "# 시각화 (seaborn 라이브러리 사용)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "Category_pivot = eBayAuctions_df.pivot_table(index='Category', values='Competitive?', aggfunc='mean')\n",
    "print(Category_pivot)\n",
    "# heatmap 시각화\n",
    "sns.heatmap(Category_pivot, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    Competitive?\n",
      "MergedCategory                                                  \n",
      "Books+Clothing/Accessories+Toys/Hobbies+Antique...      0.564437\n",
      "Coins/Stamps                                            0.297297\n",
      "Electronics+Photography                                 0.808824\n",
      "EverythingElse                                          0.235294\n",
      "Health/Beauty                                           0.171875\n",
      "Home/Garden+Computer+Business/Industrial                0.660256\n",
      "Pottery/Glass+Automotive+Jewelry                        0.357143\n",
      "SportingGoods                                           0.725806\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 데이터프레임 생성 (샘플 데이터)\n",
    "eBayAuctions_df\n",
    "\n",
    "# 범주별 평균값 계산\n",
    "category_means = eBayAuctions_df.groupby(\"Category\")[\"Competitive?\"].mean()\n",
    "\n",
    "# 오차 범위 내 병합을 위한 함수\n",
    "def merge_categories(category_means, tolerance=0.05):\n",
    "    category_means = category_means.sort_values()  # 오름차순 정렬\n",
    "    groups = []  # 병합 결과 저장\n",
    "    current_group = []\n",
    "    current_mean = None\n",
    "\n",
    "    for category, mean in category_means.items():\n",
    "        if current_group and abs(current_mean - mean) > tolerance:\n",
    "            groups.append(current_group)\n",
    "            current_group = []\n",
    "        current_group.append(category)\n",
    "        current_mean = mean\n",
    "    if current_group:\n",
    "        groups.append(current_group)\n",
    "\n",
    "    # 병합된 그룹 반환 (카테고리 이름들을 \"-\"로 연결)\n",
    "    return {cat: \"+\".join(group) for group in groups for cat in group}\n",
    "\n",
    "# 병합된 그룹 생성\n",
    "merged_groups = merge_categories(category_means)\n",
    "\n",
    "# 데이터프레임에 병합된 그룹 추가\n",
    "eBayAuctions_df[\"MergedCategory\"] = eBayAuctions_df[\"Category\"].map(merged_groups)\n",
    "\n",
    "merged_Category_pivot = eBayAuctions_df.pivot_table(index='MergedCategory', \n",
    "                                       values='Competitive?', \n",
    "                                       aggfunc='mean')\n",
    "print(merged_Category_pivot)\n",
    "# heatmap 시각화\n",
    "sns.heatmap(merged_Category_pivot, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# currency(통화)\n",
    "- EUR: 유로\n",
    "- GBP: 파운드 스털링(영국 외 9개 국가)\n",
    "- US: 달러"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Competitive?\n",
      "currency              \n",
      "EUR           0.551595\n",
      "GBP           0.687075\n",
      "US            0.519350\n"
     ]
    }
   ],
   "source": [
    "currency_pivot = eBayAuctions_df.pivot_table(index='currency', values='Competitive?', aggfunc='mean')\n",
    "print(currency_pivot)\n",
    "# heatmap 시각화\n",
    "sns.heatmap(currency_pivot, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## endDay(경매 종료일)\n",
    "- Monday\n",
    "- Tuesday\n",
    "- Wednsday\n",
    "- Thursday\n",
    "- Friday\n",
    "- Saturday\n",
    "- Sunday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Competitive?\n",
      "endDay              \n",
      "Fri         0.466899\n",
      "Mon         0.673358\n",
      "Sat         0.427350\n",
      "Sun         0.485207\n",
      "Thu         0.603960\n",
      "Tue         0.532164\n",
      "Wed         0.480000\n"
     ]
    }
   ],
   "source": [
    "endDay_pivot = eBayAuctions_df.pivot_table(index='endDay', values='Competitive?', aggfunc='mean')\n",
    "print(endDay_pivot)\n",
    "# heatmap 시각화\n",
    "sns.heatmap(endDay_pivot, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Competitive?\n",
      "Merged_endDay              \n",
      "Fri+Wed+Sun        0.477143\n",
      "Mon                0.673358\n",
      "Sat                0.427350\n",
      "Thu                0.603960\n",
      "Tue                0.532164\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "eBayAuctions_df\n",
    "\n",
    "# 범주별 평균값 계산\n",
    "endDay_means = eBayAuctions_df.groupby(\"endDay\")[\"Competitive?\"].mean()\n",
    "\n",
    "# 병합된 그룹 생성\n",
    "merged_groups = merge_categories(endDay_means, 0.02)\n",
    "\n",
    "# 데이터프레임에 병합된 그룹 추가\n",
    "eBayAuctions_df[\"Merged_endDay\"] = eBayAuctions_df[\"endDay\"].map(merged_groups)\n",
    "\n",
    "merged_endDay_pivot = eBayAuctions_df.pivot_table(index='Merged_endDay', \n",
    "                                                  values='Competitive?', \n",
    "                                                  aggfunc='mean')\n",
    "print(merged_endDay_pivot)\n",
    "# heatmap 시각화\n",
    "sns.heatmap(merged_endDay_pivot, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Duration(경매기간)\n",
    "- 1\n",
    "- 3\n",
    "- 5\n",
    "- 7\n",
    "- 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Competitive?\n",
      "Duration              \n",
      "1             0.521739\n",
      "3             0.450704\n",
      "5             0.686695\n",
      "7             0.489142\n",
      "10            0.544554\n"
     ]
    }
   ],
   "source": [
    "Duration_pivot = eBayAuctions_df.pivot_table(index='Duration', values='Competitive?', aggfunc='mean')\n",
    "print(Duration_pivot)\n",
    "# heatmap 시각화\n",
    "sns.heatmap(Duration_pivot, cmap='coolwarm')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def circle_labeling(data, colum_name):\n",
    "    data[colum_name] = pd.Categorical(data[colum_name])\n",
    "    data[colum_name] = data[colum_name].cat.codes\n",
    "    category_num = len(data[colum_name].unique())\n",
    "    embedding = np.array(data[colum_name].values)\n",
    "    #for unique_num in category:\n",
    "    embedding = 2 * np.pi * embedding / category_num \n",
    "    dim1 = np.sin(embedding)\n",
    "    dim2 = np.cos(embedding)\n",
    "    data[colum_name + \"emb_dim_1\"] = dim1\n",
    "    data[colum_name + \"emb_dim_2\"] = dim2\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept  -0.14641848602841676\n",
      "       ClosePrice  OpenPrice  Category_Antique/Art/Craft  Category_Automotive  \\\n",
      "coeff       0.091     -0.108                       0.296               -0.393   \n",
      "\n",
      "       Category_Books  Category_Business/Industrial  Category_Clothing/Accessories  \\\n",
      "coeff           0.484                         1.437                         -1.134   \n",
      "\n",
      "       Category_Coins/Stamps  Category_Collectibles  Category_Computer  Category_Electronics  \\\n",
      "coeff                 -1.923                  0.123              0.071                 0.637   \n",
      "\n",
      "       Category_EverythingElse  Category_Health/Beauty  Category_Home/Garden  \\\n",
      "coeff                   -1.299                  -1.631                 0.151   \n",
      "\n",
      "       Category_Jewelry  Category_Music/Movie/Game  Category_Photography  \\\n",
      "coeff            -0.526                      0.316                 2.997   \n",
      "\n",
      "       Category_Pottery/Glass  Category_SportingGoods  Category_Toys/Hobbies  currency_EUR  \\\n",
      "coeff                   0.006                   -0.11                  0.351        -0.771   \n",
      "\n",
      "       currency_GBP  currency_US  Duration_1  Duration_3  Duration_5  Duration_7  \\\n",
      "coeff         0.991       -0.367       -0.48       -0.15       0.344      -0.008   \n",
      "\n",
      "       Duration_10  endDay_Fri  endDay_Mon  endDay_Sat  endDay_Sun  endDay_Thu  endDay_Tue  \\\n",
      "coeff        0.147        0.27       0.498      -0.199      -0.112      -0.285       0.101   \n",
      "\n",
      "       endDay_Wed  \n",
      "coeff       -0.42  \n",
      "\n",
      "AIC 1185.5887731316363\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "범주형 예측 변수들에 대해서 더비 변수 생성\n",
    "범주형 변수: Category, currency, endDay, Duration\n",
    "'''\n",
    "\n",
    "#=========== LabelEncoder  / circle_labeling ===========#\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "preprocessed_df = eBayAuctions_df.copy()\n",
    "preprocessed_df['Category'] = le.fit_transform(preprocessed_df['Category'])\n",
    "preprocessed_df['currency'] = le.fit_transform(eBayAuctions_df['currency'])\n",
    "preprocessed_df['endDay'] = le.fit_transform(eBayAuctions_df['endDay'])\n",
    "# preprocessed_df['Duration'] = le.fit_transform(eBayAuctions_df['Duration'])\n",
    "preprocessed_df = circle_labeling(preprocessed_df, 'endDay')\n",
    "preprocessed_df['MergedCategory'] = le.fit_transform(eBayAuctions_df['MergedCategory'])\n",
    "preprocessed_df['Merged_endDay'] = le.fit_transform(eBayAuctions_df['Merged_endDay'])\n",
    "preprocessed_df\n",
    "\n",
    "\n",
    "\n",
    "#==================== get_dummies ====================#\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from dmba.metric import AIC_score\n",
    "\n",
    "# convert to categorical\n",
    "eBayAuctions_df.Category = eBayAuctions_df.Category.astype('category')\n",
    "eBayAuctions_df.currency = eBayAuctions_df.currency.astype('category')\n",
    "eBayAuctions_df.Duration = eBayAuctions_df.Duration.astype('category')\n",
    "eBayAuctions_df.endDay = eBayAuctions_df.endDay.astype('category')\n",
    "\n",
    "predictors = ['Category', 'currency', 'Duration', 'endDay', 'ClosePrice', 'OpenPrice']\n",
    "outcome = 'Competitive?'\n",
    "\n",
    "X = pd.get_dummies(eBayAuctions_df[predictors])\n",
    "y = eBayAuctions_df[outcome]\n",
    "\n",
    "# split into training and validation\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(X, y, test_size=0.4,\n",
    "                                                      random_state=1)\n",
    "\n",
    "logit_full = LogisticRegression(penalty=\"l2\", C=1e42, solver='liblinear')\n",
    "logit_full.fit(train_X, train_y)\n",
    "\n",
    "pd.set_option('display.width', 95)\n",
    "pd.set_option('display.precision',3)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "print('intercept ', logit_full.intercept_[0])\n",
    "\n",
    "print(pd.DataFrame({'coeff': logit_full.coef_[0]}, index=X.columns).transpose())\n",
    "print()\n",
    "print('AIC', AIC_score(valid_y, logit_full.predict(valid_X), df=len(train_X.columns) + 1))\n",
    "pd.reset_option('display.width')\n",
    "pd.reset_option('display.precision')\n",
    "pd.reset_option('display.max_columns')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 데이터를 학습 데이터셋(60%)과 검증 데이터셋(40%)으로 분할한다. 컷오프 값을 0.5로 하여 모든 예측 변수들을 사용한 로지스틱 모델을 실행하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "def get_statistics(model, intercept=0, coef=[], train_df=None, target_df=None):\n",
    "    print(\"Coefficient :\", coef)\n",
    "    print(\"Intercept :\", intercept)\n",
    "    \n",
    "    params = np.append(intercept, coef)\n",
    "    print(\"Params:\", params)\n",
    "\n",
    "    #prediction = model.predict(train_df.values.reshape(-1, 1))        # 단변량\n",
    "    prediction = model.predict(train_df.values)                     # 다변량\n",
    "\n",
    "    if len(prediction.shape) == 1:\n",
    "        prediction = np.expand_dims(prediction, axis=1)\n",
    "    print(train_df.columns)\n",
    "\n",
    "    new_trainset = pd.DataFrame({\"Constant\": np.ones(len(train_df.values))}).join(pd.DataFrame(train_df.values))\n",
    "    print(new_trainset)\n",
    "\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    MSE = mean_squared_error(prediction, target_df.values)\n",
    "    print(\"MSE :\", MSE)\n",
    "\n",
    "    variance = MSE * (np.linalg.inv(np.dot(new_trainset.T, new_trainset)).diagonal())       # MSE = (1, ) & else = (n, ) 가 나와야 함.\n",
    "\n",
    "    std_error = np.sqrt(variance)\n",
    "    t_values = params / std_error\n",
    "    p_values = [2 * (1 - stats.t.cdf(np.abs(i), (len(new_trainset) - len(new_trainset.columns) - 1))) for i in t_values]\n",
    "\n",
    "    std_error = np.round(std_error, 3)\n",
    "    t_values = np.round(t_values, 3)\n",
    "    p_values = np.round(p_values, 3)\n",
    "    params = np.round(params, 4)\n",
    "\n",
    "    statistics = pd.DataFrame()\n",
    "    statistics[\"Coefficients\"], statistics[\"Standard Errors\"], statistics[\"t -values\"], statistics[\"p-values\"] = [params, std_error, t_values, p_values]\n",
    "    statistics[\"variables\"] = [\"const\"] + list(train_df.columns)\n",
    "    \n",
    "    return statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Category', 'currency', 'sellerRating', 'Duration', 'endDay',\n",
      "       'ClosePrice', 'OpenPrice', 'endDayemb_dim_1', 'endDayemb_dim_2'],\n",
      "      dtype='object')\n",
      "intercept  -0.3476161229936271\n",
      "       Category  currency  sellerRating  Duration    endDay  ClosePrice  \\\n",
      "coeff  0.036485  0.277425     -0.000041 -0.004843 -0.167303    0.088114   \n",
      "\n",
      "       OpenPrice  endDayemb_dim_1  endDayemb_dim_2  \n",
      "coeff  -0.109879        -0.335092        -0.056418  \n",
      "\n",
      "AIC 1090.6977790579342\n",
      "      actual      p(0)      p(1)  predicted\n",
      "1287       0  0.739944  0.260056          0\n",
      "1017       1  0.162643  0.837357          1\n",
      "1047       0  0.607388  0.392612          0\n",
      "108        1  0.343146  0.656854          1\n",
      "1084       1  0.508268  0.491732          0\n",
      "...      ...       ...       ...        ...\n",
      "1118       1  0.564449  0.435551          0\n",
      "395        0  0.691286  0.308714          0\n",
      "1564       0  0.718164  0.281836          0\n",
      "1698       1  0.030811  0.969189          1\n",
      "1665       1  0.039036  0.960964          1\n",
      "\n",
      "[789 rows x 4 columns]\n",
      "Confusion Matrix (Accuracy 0.7878)\n",
      "\n",
      "       Prediction\n",
      "Actual   0   1\n",
      "     0 468  85\n",
      "     1 166 464\n",
      "Confusion Matrix (Accuracy 0.7731)\n",
      "\n",
      "       Prediction\n",
      "Actual   0   1\n",
      "     0 306  47\n",
      "     1 132 304\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from dmba.metric import AIC_score\n",
    "from dmba import classificationSummary\n",
    "\n",
    "original_df = pd.read_csv('../data/eBayAuctions.csv')\n",
    "y = original_df['Competitive?']\n",
    "X = preprocessed_df.drop(['Competitive?'], axis=1)\n",
    "#X = X.drop(['Group'], axis=1)\n",
    "X = X.drop(['MergedCategory'], axis=1)\n",
    "X = X.drop(['Merged_endDay'], axis=1)\n",
    "print(X.columns)\n",
    "\n",
    "# partition data\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(X, y, test_size=0.4, random_state=1)\n",
    "\n",
    "# fit a logistic regression (set penalty=l2 and C=1e42 to avoid regularization)\n",
    "logit_reg = LogisticRegression(penalty=\"l2\", C=1e42, solver='liblinear')\n",
    "logit_reg.fit(train_X, train_y)\n",
    "\n",
    "logit_reg_pred = logit_reg.predict(valid_X)\n",
    "logit_reg_proba = logit_reg.predict_proba(valid_X)\n",
    "logit_result = pd.DataFrame({'actual': valid_y,\n",
    "                             'p(0)': [p[0] for p in logit_reg_proba],\n",
    "                             'p(1)': [p[1] for p in logit_reg_proba],\n",
    "                             'predicted': logit_reg_pred })\n",
    "\n",
    "print('intercept ', logit_reg.intercept_[0])\n",
    "print(pd.DataFrame({'coeff': logit_reg.coef_[0]}, index=X.columns).transpose())\n",
    "print()\n",
    "print('AIC', AIC_score(valid_y, logit_reg.predict(valid_X), df = len(train_X.columns) + 1))\n",
    "\n",
    "logit_reg_pred = logit_reg.predict(valid_X)\n",
    "# logit_reg_proba = logit_reg.predict_proba(valid_X)\n",
    "cutoff = 0.5  # 원하는 cutoff 값 설정\n",
    "logit_reg_pred = (logit_reg.predict_proba(valid_X)[:, 1] >= cutoff).astype(int)\n",
    "\n",
    "logit_result = pd.DataFrame({'actual': valid_y,\n",
    "                             'p(0)': [p[0] for p in logit_reg_proba],\n",
    "                             'p(1)': [p[1] for p in logit_reg_proba],\n",
    "                             'predicted': logit_reg_pred })\n",
    "\n",
    "print(logit_result)\n",
    "\n",
    "classificationSummary(train_y, logit_reg.predict(train_X))\n",
    "classificationSummary(valid_y, logit_reg.predict(valid_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient : [ 3.64849641e-02  2.77425263e-01 -4.11504602e-05 -4.84330473e-03\n",
      " -1.67303121e-01  8.81138666e-02 -1.09879203e-01 -3.35091871e-01\n",
      " -5.64184230e-02]\n",
      "Intercept : -0.3476161229936271\n",
      "Params: [-3.47616123e-01  3.64849641e-02  2.77425263e-01 -4.11504602e-05\n",
      " -4.84330473e-03 -1.67303121e-01  8.81138666e-02 -1.09879203e-01\n",
      " -3.35091871e-01 -5.64184230e-02]\n",
      "Index(['Category', 'currency', 'sellerRating', 'Duration', 'endDay',\n",
      "       'ClosePrice', 'OpenPrice', 'endDayemb_dim_1', 'endDayemb_dim_2'],\n",
      "      dtype='object')\n",
      "      Constant     0    1       2     3    4       5      6         7  \\\n",
      "0          1.0   6.0  0.0   578.0  10.0  1.0    4.93   2.45  0.781831   \n",
      "1          1.0   0.0  2.0  2349.0   7.0  0.0    5.61   3.60  0.000000   \n",
      "2          1.0   6.0  0.0   884.0  10.0  1.0    2.45   2.45  0.781831   \n",
      "3          1.0   0.0  2.0  2349.0   7.0  0.0    5.50   3.60  0.000000   \n",
      "4          1.0  13.0  0.0   104.0   7.0  1.0    3.07   1.23  0.781831   \n",
      "...        ...   ...  ...     ...   ...  ...     ...    ...       ...   \n",
      "1178       1.0   1.0  2.0  2427.0   3.0  3.0   33.95  33.95  0.433884   \n",
      "1179       1.0   6.0  2.0  2046.0   5.0  0.0    7.50   7.50  0.000000   \n",
      "1180       1.0  17.0  2.0   534.0   7.0  3.0  154.23  79.99  0.433884   \n",
      "1181       1.0   6.0  0.0  1853.0  10.0  5.0    1.23   1.23 -0.974928   \n",
      "1182       1.0   0.0  2.0  4390.0   7.0  0.0    6.99   6.99  0.000000   \n",
      "\n",
      "             8  \n",
      "0     0.623490  \n",
      "1     1.000000  \n",
      "2     0.623490  \n",
      "3     1.000000  \n",
      "4     0.623490  \n",
      "...        ...  \n",
      "1178 -0.900969  \n",
      "1179  1.000000  \n",
      "1180 -0.900969  \n",
      "1181 -0.222521  \n",
      "1182  1.000000  \n",
      "\n",
      "[1183 rows x 10 columns]\n",
      "MSE : 0.2121724429416737\n",
      "   Coefficients  Standard Errors  t -values  p-values\n",
      "0       -0.3476            0.080     -4.331     0.000\n",
      "1        0.0365            0.002     14.660     0.000\n",
      "2        0.2774            0.019     14.503     0.000\n",
      "3       -0.0000            0.000    -17.339     0.000\n",
      "4       -0.0048            0.008     -0.605     0.546\n",
      "5       -0.1673            0.017    -10.018     0.000\n",
      "6        0.0881            0.000    537.493     0.000\n",
      "7       -0.1099            0.000   -310.727     0.000\n",
      "8       -0.3351            0.033    -10.238     0.000\n",
      "9       -0.0564            0.030     -1.881     0.060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/minseo/anaconda3/envs/dvg/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pice = get_statistics(logit_reg, logit_reg.intercept_[0], logit_reg.coef_[0], train_X, train_y)\n",
    "print(pice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['currency', 'sellerRating', 'Duration', 'ClosePrice', 'OpenPrice',\n",
      "       'MergedCategory', 'Merged_endDay', 'endDayemb_dim_1',\n",
      "       'endDayemb_dim_2'],\n",
      "      dtype='object')\n",
      "intercept  -0.08510583190724684\n",
      "       currency  sellerRating  Duration  ClosePrice  OpenPrice  \\\n",
      "coeff  0.197744     -0.000031 -0.053684    0.087004  -0.107128   \n",
      "\n",
      "       MergedCategory  Merged_endDay  endDayemb_dim_1  endDayemb_dim_2  \n",
      "coeff       -0.076706       0.089572        -0.017426         0.200893  \n",
      "\n",
      "AIC 1007.0784222223199\n",
      "      actual      p(0)      p(1)  predicted\n",
      "1287       0  0.693263  0.306737          0\n",
      "1017       1  0.216881  0.783119          1\n",
      "1047       0  0.587828  0.412172          0\n",
      "108        1  0.326313  0.673687          1\n",
      "1084       1  0.371907  0.628093          1\n",
      "...      ...       ...       ...        ...\n",
      "1118       1  0.544907  0.455093          0\n",
      "395        0  0.738270  0.261730          0\n",
      "1564       0  0.685283  0.314717          0\n",
      "1698       1  0.017695  0.982305          1\n",
      "1665       1  0.038074  0.961926          1\n",
      "\n",
      "[789 rows x 4 columns]\n",
      "Confusion Matrix (Accuracy 0.7802)\n",
      "\n",
      "       Prediction\n",
      "Actual   0   1\n",
      "     0 479  74\n",
      "     1 186 444\n",
      "Confusion Matrix (Accuracy 0.7959)\n",
      "\n",
      "       Prediction\n",
      "Actual   0   1\n",
      "     0 315  38\n",
      "     1 123 313\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from dmba.metric import AIC_score\n",
    "\n",
    "original_df = pd.read_csv('../data/eBayAuctions.csv')\n",
    "y = original_df['Competitive?']\n",
    "X = preprocessed_df.drop(['Competitive?'], axis=1)\n",
    "#X = X.drop(['Group'], axis=1)\n",
    "X = X.drop(['Category'], axis=1)\n",
    "X = X.drop(['endDay'], axis=1)\n",
    "print(X.columns)\n",
    "\n",
    "\n",
    "# partition data\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(X, y, test_size=0.4, random_state=1)\n",
    "\n",
    "# fit a logistic regression (set penalty=l2 and C=1e42 to avoid regularization)\n",
    "logit_reg = LogisticRegression(penalty=\"l2\", C=1e42, solver='liblinear')\n",
    "logit_reg.fit(train_X, train_y)\n",
    "\n",
    "logit_reg_pred = logit_reg.predict(valid_X)\n",
    "logit_reg_proba = logit_reg.predict_proba(valid_X)\n",
    "logit_result = pd.DataFrame({'actual': valid_y,\n",
    "                             'p(0)': [p[0] for p in logit_reg_proba],\n",
    "                             'p(1)': [p[1] for p in logit_reg_proba],\n",
    "                             'predicted': logit_reg_pred })\n",
    "\n",
    "print('intercept ', logit_reg.intercept_[0])\n",
    "print(pd.DataFrame({'coeff': logit_reg.coef_[0]}, index=X.columns).transpose())\n",
    "print()\n",
    "print('AIC', AIC_score(valid_y, logit_reg.predict(valid_X), df = len(train_X.columns) + 1))\n",
    "\n",
    "logit_reg_pred = logit_reg.predict(valid_X)\n",
    "# logit_reg_proba = logit_reg.predict_proba(valid_X)\n",
    "cutoff = 0.5  # 원하는 cutoff 값 설정\n",
    "logit_reg_pred = (logit_reg.predict_proba(valid_X)[:, 1] >= cutoff).astype(int)\n",
    "\n",
    "logit_result = pd.DataFrame({'actual': valid_y,\n",
    "                             'p(0)': [p[0] for p in logit_reg_proba],\n",
    "                             'p(1)': [p[1] for p in logit_reg_proba],\n",
    "                             'predicted': logit_reg_pred })\n",
    "\n",
    "print(logit_result)\n",
    "\n",
    "classificationSummary(train_y, logit_reg.predict(train_X))\n",
    "classificationSummary(valid_y, logit_reg.predict(valid_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 경매가 경쟁적인 경매인지 아닌지를 경매 시작 시점에서 예측하길 원한다면 경매 종가에 대한 정보를 사용할 수 없다. 경매 종가를 제외한 모든 예측변수를 이용해 앞에서와 같이 로지스틱 모델을 실행하시오. 이러한 모델은 예측 정확도 관점에서 모든 예측변수를 사용한 모델과 어떻게 비교되는가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Category', 'currency', 'sellerRating', 'Duration', 'endDay',\n",
      "       'OpenPrice', 'endDayemb_dim_1', 'endDayemb_dim_2'],\n",
      "      dtype='object')\n",
      "intercept  0.12925897893382807\n",
      "       Category  currency  sellerRating  Duration    endDay  OpenPrice  \\\n",
      "coeff  0.035867 -0.013985     -0.000014  -0.03587  0.034044  -0.009212   \n",
      "\n",
      "       endDayemb_dim_1  endDayemb_dim_2  \n",
      "coeff          0.03654         0.283751  \n",
      "\n",
      "AIC 1606.4069232873217\n",
      "      actual      p(0)      p(1)  predicted\n",
      "1287       0  0.587517  0.412483          0\n",
      "1017       1  0.410518  0.589482          1\n",
      "1047       0  0.524054  0.475946          0\n",
      "108        1  0.358734  0.641266          1\n",
      "1084       1  0.527029  0.472971          0\n",
      "...      ...       ...       ...        ...\n",
      "1118       1  0.524054  0.475946          0\n",
      "395        0  0.501375  0.498625          0\n",
      "1564       0  0.425609  0.574391          1\n",
      "1698       1  0.505367  0.494633          0\n",
      "1665       1  0.367488  0.632512          1\n",
      "\n",
      "[789 rows x 4 columns]\n",
      "Confusion Matrix (Accuracy 0.5926)\n",
      "\n",
      "       Prediction\n",
      "Actual   0   1\n",
      "     0 211 342\n",
      "     1 140 490\n",
      "Confusion Matrix (Accuracy 0.5627)\n",
      "\n",
      "       Prediction\n",
      "Actual   0   1\n",
      "     0 115 238\n",
      "     1 107 329\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from dmba.metric import AIC_score\n",
    "\n",
    "original_df = pd.read_csv('../data/eBayAuctions.csv')\n",
    "y = original_df['Competitive?']\n",
    "X = preprocessed_df.drop(['Competitive?'], axis=1)\n",
    "#X = X.drop(['Group'], axis=1)\n",
    "X = X.drop(['MergedCategory'], axis=1)\n",
    "X = X.drop(['Merged_endDay'], axis=1)\n",
    "X = X.drop(['ClosePrice'], axis=1)\n",
    "print(X.columns)\n",
    "\n",
    "# partition data\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(X, y, test_size=0.4, random_state=1)\n",
    "\n",
    "# fit a logistic regression (set penalty=l2 and C=1e42 to avoid regularization)\n",
    "logit_reg = LogisticRegression(penalty=\"l2\", C=1e42, solver='liblinear')\n",
    "logit_reg.fit(train_X, train_y)\n",
    "\n",
    "logit_reg_pred = logit_reg.predict(valid_X)\n",
    "logit_reg_proba = logit_reg.predict_proba(valid_X)\n",
    "logit_result = pd.DataFrame({'actual': valid_y,\n",
    "                             'p(0)': [p[0] for p in logit_reg_proba],\n",
    "                             'p(1)': [p[1] for p in logit_reg_proba],\n",
    "                             'predicted': logit_reg_pred })\n",
    "\n",
    "print('intercept ', logit_reg.intercept_[0])\n",
    "print(pd.DataFrame({'coeff': logit_reg.coef_[0]}, index=X.columns).transpose())\n",
    "print()\n",
    "print('AIC', AIC_score(valid_y, logit_reg.predict(valid_X), df = len(train_X.columns) + 1))\n",
    "\n",
    "logit_reg_pred = logit_reg.predict(valid_X)\n",
    "# logit_reg_proba = logit_reg.predict_proba(valid_X)\n",
    "cutoff = 0.5  # 원하는 cutoff 값 설정\n",
    "logit_reg_pred = (logit_reg.predict_proba(valid_X)[:, 1] >= cutoff).astype(int)\n",
    "\n",
    "logit_result = pd.DataFrame({'actual': valid_y,\n",
    "                             'p(0)': [p[0] for p in logit_reg_proba],\n",
    "                             'p(1)': [p[1] for p in logit_reg_proba],\n",
    "                             'predicted': logit_reg_pred })\n",
    "\n",
    "print(logit_result)\n",
    "\n",
    "classificationSummary(train_y, logit_reg.predict(train_X))\n",
    "classificationSummary(valid_y, logit_reg.predict(valid_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 경매 종가에 대한 회귀 계수의 의미를 해석하시오. 경매 종가는 실질적인 의미가 있는가? 경매 종가를 이용해 경쟁적인 경매를 예측하는 것이 통계적으로 의미가 있는가? (유의수준 10% 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient : [ 3.58671580e-02 -1.39847972e-02 -1.44006653e-05 -3.58698472e-02\n",
      "  3.40439073e-02 -9.21192460e-03  3.65403437e-02  2.83750633e-01]\n",
      "Intercept : 0.12925897893382807\n",
      "Params: [ 1.29258979e-01  3.58671580e-02 -1.39847972e-02 -1.44006653e-05\n",
      " -3.58698472e-02  3.40439073e-02 -9.21192460e-03  3.65403437e-02\n",
      "  2.83750633e-01]\n",
      "Index(['Category', 'currency', 'sellerRating', 'Duration', 'endDay',\n",
      "       'OpenPrice', 'endDayemb_dim_1', 'endDayemb_dim_2'],\n",
      "      dtype='object')\n",
      "      Constant     0    1       2     3    4      5         6         7\n",
      "0          1.0   6.0  0.0   578.0  10.0  1.0   2.45  0.781831  0.623490\n",
      "1          1.0   0.0  2.0  2349.0   7.0  0.0   3.60  0.000000  1.000000\n",
      "2          1.0   6.0  0.0   884.0  10.0  1.0   2.45  0.781831  0.623490\n",
      "3          1.0   0.0  2.0  2349.0   7.0  0.0   3.60  0.000000  1.000000\n",
      "4          1.0  13.0  0.0   104.0   7.0  1.0   1.23  0.781831  0.623490\n",
      "...        ...   ...  ...     ...   ...  ...    ...       ...       ...\n",
      "1178       1.0   1.0  2.0  2427.0   3.0  3.0  33.95  0.433884 -0.900969\n",
      "1179       1.0   6.0  2.0  2046.0   5.0  0.0   7.50  0.000000  1.000000\n",
      "1180       1.0  17.0  2.0   534.0   7.0  3.0  79.99  0.433884 -0.900969\n",
      "1181       1.0   6.0  0.0  1853.0  10.0  5.0   1.23 -0.974928 -0.222521\n",
      "1182       1.0   0.0  2.0  4390.0   7.0  0.0   6.99  0.000000  1.000000\n",
      "\n",
      "[1183 rows x 9 columns]\n",
      "MSE : 0.4074387151310228\n",
      "   Coefficients  Standard Errors  t -values  p-values\n",
      "0        0.1293            0.111      1.166     0.244\n",
      "1        0.0359            0.003     10.400     0.000\n",
      "2       -0.0140            0.026     -0.528     0.597\n",
      "3       -0.0000            0.000     -4.381     0.000\n",
      "4       -0.0359            0.011     -3.237     0.001\n",
      "5        0.0340            0.023      1.472     0.141\n",
      "6       -0.0092            0.000    -21.469     0.000\n",
      "7        0.0365            0.045      0.807     0.420\n",
      "8        0.2838            0.042      6.834     0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/minseo/anaconda3/envs/dvg/lib/python3.12/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pice = get_statistics(logit_reg, logit_reg.intercept_[0], logit_reg.coef_[0], train_X, train_y)\n",
    "print(pice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Archive - Previous e,f solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [6장 다중선형회귀]에서 설명한 대로 단계적 회귀(stepwise regression)를 사용해 학습 데이터셋에 가장 잘 적합된(정확도가 가장 높은) 모델을 찾으시오. 어떤 예측변수가 사용되는가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "def stepwise_selection(data_x, data_y):\n",
    "    # 초기화\n",
    "    startpoint = time.time()\n",
    "    selected_features = []\n",
    "    best_aic = float(\"inf\")  # 초기 AIC를 무한대로 설정\n",
    "    loopCount = 0\n",
    "\n",
    "    while True:\n",
    "        added = None\n",
    "        removed = None\n",
    "        # Forward Selection\n",
    "        for feature in data_x.columns:\n",
    "            if feature not in selected_features:\n",
    "                temp_features = selected_features + [feature]\n",
    "                \n",
    "                model = sm.Logit(data_y, sm.add_constant(data_x[temp_features])).fit(method = 'bfgs')\n",
    "                aic = model.aic\n",
    "                if aic < best_aic:\n",
    "                    best_aic = aic\n",
    "                    added = feature\n",
    "                    \n",
    "                    \n",
    "        # Backward Elimination\n",
    "        if len(selected_features) > 0:\n",
    "            for feature in selected_features:\n",
    "                temp_features = [f for f in selected_features if f != feature]\n",
    "                model = sm.Logit(data_y, sm.add_constant(data_x[temp_features])).fit(method = 'bfgs')\n",
    "                aic = model.aic\n",
    "                if aic < best_aic:\n",
    "                    best_aic = aic\n",
    "                    removed = feature\n",
    "        if added is not None:\n",
    "            selected_features.append(added)\n",
    "        elif removed is not None:\n",
    "            selected_features.remove(removed)\n",
    "        else:\n",
    "            break\n",
    "        time.sleep(1)\n",
    "        loopCount += 1\n",
    "    #print(\"Best selected features:\", selected_features)\n",
    "    #print(\"Best AIC:\", best_aic)\n",
    "\n",
    "    return selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['currency', 'sellerRating', 'Duration', 'OpenPrice', 'MergedCategory',\n",
      "       'Merged_endDay', 'endDayemb_dim_1', 'endDayemb_dim_2'],\n",
      "      dtype='object')\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.690917\n",
      "         Iterations: 9\n",
      "         Function evaluations: 10\n",
      "         Gradient evaluations: 10\n",
      "         Current function value: 0.693147\n",
      "         Iterations: 0\n",
      "         Function evaluations: 13\n",
      "         Gradient evaluations: 2\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.690785\n",
      "         Iterations: 11\n",
      "         Function evaluations: 13\n",
      "         Gradient evaluations: 13\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.682771\n",
      "         Iterations: 8\n",
      "         Function evaluations: 12\n",
      "         Gradient evaluations: 12\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.690244\n",
      "         Iterations: 4\n",
      "         Function evaluations: 5\n",
      "         Gradient evaluations: 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.690684\n",
      "         Iterations: 7\n",
      "         Function evaluations: 8\n",
      "         Gradient evaluations: 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.690533\n",
      "         Iterations: 8\n",
      "         Function evaluations: 9\n",
      "         Gradient evaluations: 9\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.688793\n",
      "         Iterations: 8\n",
      "         Function evaluations: 9\n",
      "         Gradient evaluations: 9\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.682728\n",
      "         Iterations: 8\n",
      "         Function evaluations: 13\n",
      "         Gradient evaluations: 13\n",
      "         Current function value: 0.693147\n",
      "         Iterations: 0\n",
      "         Function evaluations: 13\n",
      "         Gradient evaluations: 2\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.681977\n",
      "         Iterations: 14\n",
      "         Function evaluations: 18\n",
      "         Gradient evaluations: 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.682735\n",
      "         Iterations: 10\n",
      "         Function evaluations: 13\n",
      "         Gradient evaluations: 13\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.682586\n",
      "         Iterations: 11\n",
      "         Function evaluations: 15\n",
      "         Gradient evaluations: 15\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.682296\n",
      "         Iterations: 13\n",
      "         Function evaluations: 17\n",
      "         Gradient evaluations: 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.680575\n",
      "         Iterations: 12\n",
      "         Function evaluations: 16\n",
      "         Gradient evaluations: 16\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.691027\n",
      "         Iterations: 4\n",
      "         Function evaluations: 5\n",
      "         Gradient evaluations: 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.680568\n",
      "         Iterations: 15\n",
      "         Function evaluations: 19\n",
      "         Gradient evaluations: 19\n",
      "         Current function value: 0.693147\n",
      "         Iterations: 0\n",
      "         Function evaluations: 13\n",
      "         Gradient evaluations: 2\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.680004\n",
      "         Iterations: 19\n",
      "         Function evaluations: 22\n",
      "         Gradient evaluations: 22\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.680498\n",
      "         Iterations: 15\n",
      "         Function evaluations: 18\n",
      "         Gradient evaluations: 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.679685\n",
      "         Iterations: 14\n",
      "         Function evaluations: 18\n",
      "         Gradient evaluations: 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.680353\n",
      "         Iterations: 16\n",
      "         Function evaluations: 20\n",
      "         Gradient evaluations: 20\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.688793\n",
      "         Iterations: 8\n",
      "         Function evaluations: 9\n",
      "         Gradient evaluations: 9\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.682771\n",
      "         Iterations: 8\n",
      "         Function evaluations: 12\n",
      "         Gradient evaluations: 12\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.679650\n",
      "         Iterations: 17\n",
      "         Function evaluations: 21\n",
      "         Gradient evaluations: 21\n",
      "         Current function value: 0.693147\n",
      "         Iterations: 0\n",
      "         Function evaluations: 13\n",
      "         Gradient evaluations: 2\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.678892\n",
      "         Iterations: 20\n",
      "         Function evaluations: 24\n",
      "         Gradient evaluations: 24\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.679617\n",
      "         Iterations: 16\n",
      "         Function evaluations: 19\n",
      "         Gradient evaluations: 19\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.678877\n",
      "         Iterations: 19\n",
      "         Function evaluations: 23\n",
      "         Gradient evaluations: 23\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.687559\n",
      "         Iterations: 11\n",
      "         Function evaluations: 12\n",
      "         Gradient evaluations: 12\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.682586\n",
      "         Iterations: 11\n",
      "         Function evaluations: 15\n",
      "         Gradient evaluations: 15\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.680575\n",
      "         Iterations: 12\n",
      "         Function evaluations: 16\n",
      "         Gradient evaluations: 16\n",
      "['OpenPrice', 'endDayemb_dim_2', 'Merged_endDay']\n",
      "Final Model Coefficients: [[-0.01003257  0.22603589  0.069605  ]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "import statsmodels.api as sm\n",
    "\n",
    "original_df = pd.read_csv('../data/eBayAuctions.csv')\n",
    "y = original_df['Competitive?']\n",
    "X = preprocessed_df.drop(['Competitive?'], axis=1)\n",
    "X = X.drop(['Category'], axis=1)\n",
    "X = X.drop(['endDay'], axis=1)\n",
    "X = X.drop(['ClosePrice'], axis=1)\n",
    "print(X.columns)\n",
    "\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(X, y, test_size=0.4, random_state=1)\n",
    "# partition data\n",
    "selected_features = stepwise_selection(train_X, train_y)\n",
    "print(selected_features)\n",
    "\n",
    "# Fit Final Model\n",
    "final_model = LogisticRegression()\n",
    "final_model.fit(train_X[selected_features], train_y)\n",
    "print(\"Final Model Coefficients:\", final_model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 검증 데이터셋에서 가장 정확도가 높은 모델을 찾기 위해 단계적 회귀(stepwise regression)를 사용하시오. 어떤 예측변수가 사용되는가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['currency', 'sellerRating', 'Duration', 'OpenPrice', 'MergedCategory',\n",
      "       'Merged_endDay', 'endDayemb_dim_1', 'endDayemb_dim_2'],\n",
      "      dtype='object')\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.690917\n",
      "         Iterations: 9\n",
      "         Function evaluations: 10\n",
      "         Gradient evaluations: 10\n",
      "         Current function value: 0.693147\n",
      "         Iterations: 0\n",
      "         Function evaluations: 13\n",
      "         Gradient evaluations: 2\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.690785\n",
      "         Iterations: 11\n",
      "         Function evaluations: 13\n",
      "         Gradient evaluations: 13\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.682771\n",
      "         Iterations: 8\n",
      "         Function evaluations: 12\n",
      "         Gradient evaluations: 12\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.690244\n",
      "         Iterations: 4\n",
      "         Function evaluations: 5\n",
      "         Gradient evaluations: 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.690684\n",
      "         Iterations: 7\n",
      "         Function evaluations: 8\n",
      "         Gradient evaluations: 8\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.690533\n",
      "         Iterations: 8\n",
      "         Function evaluations: 9\n",
      "         Gradient evaluations: 9\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.688793\n",
      "         Iterations: 8\n",
      "         Function evaluations: 9\n",
      "         Gradient evaluations: 9\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.682728\n",
      "         Iterations: 8\n",
      "         Function evaluations: 13\n",
      "         Gradient evaluations: 13\n",
      "         Current function value: 0.693147\n",
      "         Iterations: 0\n",
      "         Function evaluations: 13\n",
      "         Gradient evaluations: 2\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.681977\n",
      "         Iterations: 14\n",
      "         Function evaluations: 18\n",
      "         Gradient evaluations: 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.682735\n",
      "         Iterations: 10\n",
      "         Function evaluations: 13\n",
      "         Gradient evaluations: 13\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.682586\n",
      "         Iterations: 11\n",
      "         Function evaluations: 15\n",
      "         Gradient evaluations: 15\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.682296\n",
      "         Iterations: 13\n",
      "         Function evaluations: 17\n",
      "         Gradient evaluations: 17\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.680575\n",
      "         Iterations: 12\n",
      "         Function evaluations: 16\n",
      "         Gradient evaluations: 16\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.691027\n",
      "         Iterations: 4\n",
      "         Function evaluations: 5\n",
      "         Gradient evaluations: 5\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.680568\n",
      "         Iterations: 15\n",
      "         Function evaluations: 19\n",
      "         Gradient evaluations: 19\n",
      "         Current function value: 0.693147\n",
      "         Iterations: 0\n",
      "         Function evaluations: 13\n",
      "         Gradient evaluations: 2\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.680004\n",
      "         Iterations: 19\n",
      "         Function evaluations: 22\n",
      "         Gradient evaluations: 22\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.680498\n",
      "         Iterations: 15\n",
      "         Function evaluations: 18\n",
      "         Gradient evaluations: 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.679685\n",
      "         Iterations: 14\n",
      "         Function evaluations: 18\n",
      "         Gradient evaluations: 18\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.680353\n",
      "         Iterations: 16\n",
      "         Function evaluations: 20\n",
      "         Gradient evaluations: 20\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.688793\n",
      "         Iterations: 8\n",
      "         Function evaluations: 9\n",
      "         Gradient evaluations: 9\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.682771\n",
      "         Iterations: 8\n",
      "         Function evaluations: 12\n",
      "         Gradient evaluations: 12\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.679650\n",
      "         Iterations: 17\n",
      "         Function evaluations: 21\n",
      "         Gradient evaluations: 21\n",
      "         Current function value: 0.693147\n",
      "         Iterations: 0\n",
      "         Function evaluations: 13\n",
      "         Gradient evaluations: 2\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.678892\n",
      "         Iterations: 20\n",
      "         Function evaluations: 24\n",
      "         Gradient evaluations: 24\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.679617\n",
      "         Iterations: 16\n",
      "         Function evaluations: 19\n",
      "         Gradient evaluations: 19\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.678877\n",
      "         Iterations: 19\n",
      "         Function evaluations: 23\n",
      "         Gradient evaluations: 23\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.687559\n",
      "         Iterations: 11\n",
      "         Function evaluations: 12\n",
      "         Gradient evaluations: 12\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.682586\n",
      "         Iterations: 11\n",
      "         Function evaluations: 15\n",
      "         Gradient evaluations: 15\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.680575\n",
      "         Iterations: 12\n",
      "         Function evaluations: 16\n",
      "         Gradient evaluations: 16\n",
      "['OpenPrice', 'endDayemb_dim_2', 'Merged_endDay']\n",
      "Final Model Coefficients: [[-0.00655369  0.07694237  0.02491751]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "import statsmodels.api as sm\n",
    "\n",
    "original_df = pd.read_csv('../data/eBayAuctions.csv')\n",
    "y = original_df['Competitive?']\n",
    "X = preprocessed_df.drop(['Competitive?'], axis=1)\n",
    "X = X.drop(['Category'], axis=1)\n",
    "X = X.drop(['endDay'], axis=1)\n",
    "X = X.drop(['ClosePrice'], axis=1)\n",
    "print(X.columns)\n",
    "\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(X, y, test_size=0.4, random_state=1)\n",
    "# partition data\n",
    "selected_features = stepwise_selection(train_X, train_y)\n",
    "print(selected_features)\n",
    "\n",
    "# Fit Final Model\n",
    "final_model = LogisticRegression()\n",
    "final_model.fit(valid_X[selected_features], valid_y)\n",
    "print(\"Final Model Coefficients:\", final_model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II - Jaeheon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e/f. 단계적 회귀 (stepwise_selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ========================= Select the best variables with a train AIC score =========================\n",
      "Variables: ClosePrice, OpenPrice, sellerRating, MergedCategory_Books+Clothing/Accessories+Toys/Hobbies+Antique/Art/Craft+Collectibles+Music/Movie/Game, MergedCategory_Coins/Stamps, MergedCategory_Electronics+Photography, MergedCategory_EverythingElse, MergedCategory_Health/Beauty, MergedCategory_Home/Garden+Computer+Business/Industrial, MergedCategory_Pottery/Glass+Automotive+Jewelry, MergedCategory_SportingGoods, currency_EUR, currency_GBP, currency_US, Duration_1, Duration_3, Duration_5, Duration_7, Duration_10, Merged_endDay_Fri+Wed+Sun, Merged_endDay_Mon, Merged_endDay_Sat, Merged_endDay_Thu, Merged_endDay_Tue\n",
      "Start: score=2615.81, constant\n",
      "Step: score=2245.77, add ClosePrice\n",
      "Step: score=1641.46, add OpenPrice\n",
      "Step: score=1481.04, add MergedCategory_Books+Clothing/Accessories+Toys/Hobbies+Antique/Art/Craft+Collectibles+Music/Movie/Game\n",
      "Step: score=1334.94, add Merged_endDay_Fri+Wed+Sun\n",
      "Step: score=1283.86, add MergedCategory_SportingGoods\n",
      "Step: score=1283.86, unchanged None\n",
      "       ClosePrice  OpenPrice  \\\n",
      "coeff       0.082     -0.098   \n",
      "\n",
      "       MergedCategory_Books+Clothing/Accessories+Toys/Hobbies+Antique/Art/Craft+Collectibles+Music/Movie/Game  \\\n",
      "coeff                                              0.528                                                        \n",
      "\n",
      "       Merged_endDay_Fri+Wed+Sun  MergedCategory_SportingGoods  \n",
      "coeff                     -0.389                         0.214  \n",
      "AIC 899.9979266969733\n",
      "\n",
      " ========================= Select the best variables with a valid AIC score =========================\n",
      "Variables: ClosePrice, OpenPrice, sellerRating, MergedCategory_Books+Clothing/Accessories+Toys/Hobbies+Antique/Art/Craft+Collectibles+Music/Movie/Game, MergedCategory_Coins/Stamps, MergedCategory_Electronics+Photography, MergedCategory_EverythingElse, MergedCategory_Health/Beauty, MergedCategory_Home/Garden+Computer+Business/Industrial, MergedCategory_Pottery/Glass+Automotive+Jewelry, MergedCategory_SportingGoods, currency_EUR, currency_GBP, currency_US, Duration_1, Duration_3, Duration_5, Duration_7, Duration_10, Merged_endDay_Fri+Wed+Sun, Merged_endDay_Mon, Merged_endDay_Sat, Merged_endDay_Thu, Merged_endDay_Tue\n",
      "Start: score=1775.11, constant\n",
      "Step: score=1523.13, add ClosePrice\n",
      "Step: score=1079.09, add OpenPrice\n",
      "Step: score=966.19, add MergedCategory_Books+Clothing/Accessories+Toys/Hobbies+Antique/Art/Craft+Collectibles+Music/Movie/Game\n",
      "Step: score=924.65, add Duration_7\n",
      "Step: score=897.53, add MergedCategory_Home/Garden+Computer+Business/Industrial\n",
      "Step: score=875.15, add MergedCategory_Health/Beauty\n",
      "Step: score=857.94, add MergedCategory_Electronics+Photography\n",
      "Step: score=840.34, add Merged_endDay_Sat\n",
      "Step: score=828.38, add MergedCategory_SportingGoods\n",
      "Step: score=822.34, remove Duration_7\n",
      "Step: score=822.34, unchanged None\n",
      "       ClosePrice  OpenPrice  \\\n",
      "coeff       0.075     -0.091   \n",
      "\n",
      "       MergedCategory_Books+Clothing/Accessories+Toys/Hobbies+Antique/Art/Craft+Collectibles+Music/Movie/Game  \\\n",
      "coeff                                              0.819                                                        \n",
      "\n",
      "       MergedCategory_Home/Garden+Computer+Business/Industrial  MergedCategory_Health/Beauty  \\\n",
      "coeff                                              0.851                              -1.057   \n",
      "\n",
      "       MergedCategory_Electronics+Photography  Merged_endDay_Sat  \\\n",
      "coeff                                   1.245             -0.507   \n",
      "\n",
      "       MergedCategory_SportingGoods  \n",
      "coeff                         0.575  \n",
      "AIC 836.335059659033\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "stepwise_selection with the example(Chapter_06_linear_regression.ipynb)\n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from dmba import stepwise_selection\n",
    "\n",
    "predictors = ['MergedCategory', 'currency', 'Duration', 'Merged_endDay', 'ClosePrice', 'OpenPrice', 'sellerRating']\n",
    "outcome = 'Competitive?'\n",
    "\n",
    "X = pd.get_dummies(eBayAuctions_df[predictors])\n",
    "y = eBayAuctions_df[outcome]\n",
    "\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(X, y, test_size=0.4, random_state=1)\n",
    "\n",
    "def train_model(variables):\n",
    "    if len(variables) == 0:\n",
    "        return None\n",
    "    model = LogisticRegression(penalty=\"l2\", C=1e42, solver='liblinear')\n",
    "    model.fit(train_X[variables], train_y)\n",
    "    return model\n",
    "\n",
    "def score_model_w_train(model, variables):\n",
    "    if len(variables) == 0:\n",
    "        return AIC_score(train_y, [int(train_y.mean())] * len(train_y), model, df=1)\n",
    "    return AIC_score(train_y, model.predict(train_X[variables]), model)\n",
    "\n",
    "def score_model_w_valid(model, variables):\n",
    "    if len(variables) == 0:\n",
    "        return AIC_score(valid_y, [int(valid_y.mean())] * len(valid_y), model, df=1)\n",
    "    return AIC_score(valid_y, model.predict(valid_X[variables]), model)\n",
    "\n",
    "\n",
    "pd.set_option('display.width', 95)\n",
    "pd.set_option('display.precision',3)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "print('\\n', '='*25, 'Select the best variables with a train AIC score', '='*25)\n",
    "best_model, best_variables = stepwise_selection(X.columns, train_model, score_model_w_train, verbose=True)\n",
    "print(pd.DataFrame({'coeff': best_model.coef_[0]}, index=best_variables).transpose())\n",
    "print('AIC', AIC_score(valid_y, best_model.predict(valid_X[best_variables]), df = len(best_variables) + 1))\n",
    "\n",
    "print('\\n', '='*25, 'Select the best variables with a valid AIC score', '='*25)\n",
    "best_model, best_variables = stepwise_selection(X.columns, train_model, score_model_w_valid, verbose=True)\n",
    "print(pd.DataFrame({'coeff': best_model.coef_[0]}, index=best_variables).transpose())\n",
    "print('AIC', AIC_score(valid_y, best_model.predict(valid_X[best_variables]), df = len(best_variables) + 1))\n",
    "\n",
    "pd.reset_option('display.width')\n",
    "pd.reset_option('display.precision')\n",
    "pd.reset_option('display.max_columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "predictors = ['MergedCategory', 'Merged_endDay']\n",
    "outcome = 'Competitive?'\n",
    "\n",
    "X = eBayAuctions_df[predictors]\n",
    "y = eBayAuctions_df[outcome]\n",
    "\n",
    "les = [LabelEncoder(), LabelEncoder()]\n",
    "for i in range(len(predictors)):\n",
    "    X[predictors[i]] = les[i].fit_transform(X[predictors[i]])\n",
    "\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(X, y, test_size=0.4, random_state=1)\n",
    "\n",
    "train_df = pd.concat([train_X, train_y], axis=1)\n",
    "valid_df = pd.concat([valid_X, valid_y], axis=1)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "figs, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(predictors)):\n",
    "    groupAverage_valid = valid_df.groupby(predictors[i])[outcome].mean()\n",
    "    groupAverage_train = train_df.groupby(predictors[i])[outcome].mean()\n",
    "\n",
    "    width = 0.4\n",
    "\n",
    "    x = range(len(groupAverage_valid))\n",
    "\n",
    "    axs[i].bar([i + width / 2 for i in x], groupAverage_train, width=width, color='tab:blue', label='Train')\n",
    "    axs[i].bar([i - width / 2 for i in x], groupAverage_valid, width=width, color='tab:orange', label='Valid')\n",
    "\n",
    "    max_label_length = 10\n",
    "    truncated_labels = [label[:max_label_length] + \"...\" if len(label) > max_label_length else label\n",
    "                        for label in les[i].inverse_transform(range(len(les[i].classes_)))]\n",
    "\n",
    "    if i == 0:\n",
    "        axs[i].set_ylabel('Average Competitive?')\n",
    "    axs[i].set_xticks(x)\n",
    "    axs[i].set_xticklabels(truncated_labels, rotation=45, ha='right')\n",
    "\n",
    "    axs[i].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - i. 학습 데이터셋에 L1 페널티가 있는 벌점화(regularized) 로지스틱 회귀를 사용한다. 이 결과(예측변수와 분류 성능)를, 가장 잘 적합한 모델 및 가장 잘 예측한 모델의 결과와 비교하시오."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================== Best model =========================\n",
      "       ClosePrice  OpenPrice  \\\n",
      "coeff       0.075     -0.091   \n",
      "\n",
      "       MergedCategory_Books+Clothing/Accessories+Toys/Hobbies+Antique/Art/Craft+Collectibles+Music/Movie/Game  \\\n",
      "coeff                                              0.819                                                        \n",
      "\n",
      "       MergedCategory_Home/Garden+Computer+Business/Industrial  MergedCategory_Health/Beauty  \\\n",
      "coeff                                              0.851                              -1.057   \n",
      "\n",
      "       MergedCategory_Electronics+Photography  Merged_endDay_Sat  \\\n",
      "coeff                                   1.245             -0.507   \n",
      "\n",
      "       MergedCategory_SportingGoods  \n",
      "coeff                         0.575  \n",
      "\n",
      "AIC 836.335059659033\n",
      "Confusion Matrix (Accuracy 0.8352)\n",
      "\n",
      "       Prediction\n",
      "Actual   0   1\n",
      "     0 332  21\n",
      "     1 109 327\n",
      "\n",
      " ================= L1-Regularized model =================\n",
      "       ClosePrice  OpenPrice  \\\n",
      "coeff       0.076     -0.092   \n",
      "\n",
      "       MergedCategory_Books+Clothing/Accessories+Toys/Hobbies+Antique/Art/Craft+Collectibles+Music/Movie/Game  \\\n",
      "coeff                                              0.668                                                        \n",
      "\n",
      "       MergedCategory_Home/Garden+Computer+Business/Industrial  MergedCategory_Health/Beauty  \\\n",
      "coeff                                              0.649                              -0.992   \n",
      "\n",
      "       MergedCategory_Electronics+Photography  Merged_endDay_Sat  \\\n",
      "coeff                                   0.893             -0.471   \n",
      "\n",
      "       MergedCategory_SportingGoods  \n",
      "coeff                         0.306  \n",
      "\n",
      "AIC 877.7153287279693\n",
      "Confusion Matrix (Accuracy 0.8264)\n",
      "\n",
      "       Prediction\n",
      "Actual   0   1\n",
      "     0 333  20\n",
      "     1 117 319\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from dmba.metric import AIC_score\n",
    "from dmba import classificationSummary, gainsChart\n",
    "\n",
    "predictors = ['MergedCategory', 'currency', 'Duration', 'Merged_endDay', 'ClosePrice', 'OpenPrice', 'sellerRating']\n",
    "outcome = 'Competitive?'\n",
    "\n",
    "X = pd.get_dummies(eBayAuctions_df[predictors])[best_variables]\n",
    "y = eBayAuctions_df[outcome]\n",
    "\n",
    "# partition data\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(X, y, test_size=0.4, random_state=1)\n",
    "\n",
    "\n",
    "########### best model ###############\n",
    "logit_best = best_model\n",
    "\n",
    "logit_best_proba = logit_best.predict_proba(valid_X)\n",
    "best_result = pd.DataFrame({'actual': valid_y,\n",
    "                            'p(0)': [p[0] for p in logit_best_proba],\n",
    "                            'p(1)': [p[1] for p in logit_best_proba],\n",
    "                            'predicted': logit_best.predict(valid_X),\n",
    "                          })\n",
    "best_result = best_result.sort_values(by=['p(1)'], ascending=False)\n",
    "\n",
    "\n",
    "########### l2-regularized model ###############\n",
    "logit_best_l2 = LogisticRegression(penalty=\"l2\", solver='liblinear')\n",
    "logit_best_l2.fit(train_X, train_y)\n",
    "\n",
    "logit_best_l2_proba = logit_best_l2.predict_proba(valid_X)\n",
    "best_l2_result = pd.DataFrame({'actual': valid_y,\n",
    "                            'p(0)': [p[0] for p in logit_best_l2_proba],\n",
    "                            'p(1)': [p[1] for p in logit_best_l2_proba],\n",
    "                            'predicted': logit_best_l2.predict(valid_X),\n",
    "                          })\n",
    "best_l2_result = best_l2_result.sort_values(by=['p(1)'], ascending=False)\n",
    "\n",
    "\n",
    "\n",
    "########### l1-regularized model ###############\n",
    "logit_l1 = LogisticRegression(penalty=\"l1\", solver='liblinear')\n",
    "logit_l1.fit(train_X, train_y)\n",
    "\n",
    "logit_l1_proba = logit_l1.predict_proba(valid_X)\n",
    "l1_result = pd.DataFrame({'actual': valid_y,\n",
    "                            'p(0)': [p[0] for p in logit_l1_proba],\n",
    "                            'p(1)': [p[1] for p in logit_l1_proba],\n",
    "                            'predicted': logit_l1.predict(valid_X),\n",
    "                          })\n",
    "l1_result = l1_result.sort_values(by=['p(1)'], ascending=False)\n",
    "\n",
    "\n",
    "pd.set_option('display.width', 95)\n",
    "pd.set_option('display.precision',3)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "print('='*20, 'Best model', '='*25)\n",
    "print(pd.DataFrame({'coeff': logit_best.coef_[0]}, index=X.columns).transpose())\n",
    "print()\n",
    "print('AIC', AIC_score(valid_y, logit_best.predict(valid_X), df=len(train_X.columns) + 1))\n",
    "classificationSummary(best_result['actual'], best_result['predicted'])\n",
    "\n",
    "# print('\\n', '='*17, 'L2-Regularized model', '='*17)\n",
    "# print(pd.DataFrame({'coeff': logit_best_l2.coef_[0]}, index=X.columns).transpose())\n",
    "# print()\n",
    "# print('AIC', AIC_score(valid_y, logit_best_l2.predict(valid_X), df=len(train_X.columns) + 1))\n",
    "# classificationSummary(best_l2_result['actual'], best_l2_result['predicted'])\n",
    "\n",
    "print('\\n', '='*17, 'L1-Regularized model', '='*17)\n",
    "print(pd.DataFrame({'coeff': logit_l1.coef_[0]}, index=X.columns).transpose())\n",
    "print()\n",
    "print('AIC', AIC_score(valid_y, logit_l1.predict(valid_X), df=len(train_X.columns) + 1))\n",
    "classificationSummary(l1_result['actual'], l1_result['predicted'])\n",
    "\n",
    "\n",
    "pd.reset_option('display.width')\n",
    "pd.reset_option('display.precision')\n",
    "pd.reset_option('display.max_columns')\n",
    "\n",
    "ax = gainsChart(best_result.actual, label='Best model', color='C1', figsize=[5, 5])\n",
    "# ax = gainsChart(best_l2_result.actual, label='L1-Regularized model', color='C1', ax=ax)\n",
    "ax = gainsChart(l1_result.actual, label='L1-Regularized model', color='C0', ax=ax)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - j. 모델 분석의 주목적이 정확한 분류라고 한다면, 어떤 컷오프 값이 사용되어야 하는가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "max_f1 = 0\n",
    "max_acc = 0\n",
    "cutoffs = []\n",
    "f1s = []\n",
    "accs = []\n",
    "for cutoff in np.arange(0.0, 1.0, 0.001):\n",
    "    cutoffs.append(cutoff)\n",
    "    logit_best_pred = (logit_best.predict_proba(valid_X)[:, 1] >= cutoff).astype(int)\n",
    "    f1 = f1_score(valid_y, logit_best_pred)\n",
    "    f1s.append(f1)\n",
    "    if f1 > max_f1:\n",
    "        max_f1 = f1\n",
    "        max_f1_cutoff = cutoff\n",
    "\n",
    "    acc = accuracy_score(valid_y, logit_best_pred)\n",
    "    accs.append(acc)\n",
    "    if acc > max_acc:\n",
    "        max_acc = acc\n",
    "        max_acc_cutoff = cutoff\n",
    "\n",
    "plt.figure(figsize=(4, 3))\n",
    "\n",
    "plt.plot(cutoffs, f1s, label='F1-score', color='tab:blue')\n",
    "plt.plot(cutoffs, accs, label='Accuracy', color='tab:orange')\n",
    "\n",
    "plt.vlines(max_acc_cutoff, 0, 1, linestyles='--', colors='gray')\n",
    "plt.text(max_f1_cutoff+0.01, 0.05, str(max_f1_cutoff), color='gray')\n",
    "plt.text(max_f1_cutoff+0.01, max_f1+0.06, str(max_f1), color='tab:blue')\n",
    "plt.text(max_acc_cutoff+0.01, max_acc, str(max_acc), color='tab:orange')\n",
    "\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - k. 이 데이터를 바탕으로 판매자가 정한 경매 조건(경매 기간, 시작가, 경매 마감 요일, 화폐 단위) 중 어떤 설정이 경쟁적인 판매로 이어질 가능성을 가장 높인다고 할 수 있겠는가?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept  0.37491744321690385\n",
      "       OpenPrice  Duration_1  Duration_3  Duration_5  Duration_7  Duration_10  \\\n",
      "coeff     -0.008       0.355      -0.115       0.382      -0.198        -0.05   \n",
      "\n",
      "       Merged_endDay_Fri+Wed+Sun  Merged_endDay_Mon  Merged_endDay_Sat  Merged_endDay_Thu  \\\n",
      "coeff                     -0.003               0.69             -0.053             -0.405   \n",
      "\n",
      "       Merged_endDay_Tue  currency_EUR  currency_GBP  currency_US  \n",
      "coeff              0.146        -0.311         1.099       -0.413  \n",
      "\n",
      "AIC 1568.8570122097267\n"
     ]
    }
   ],
   "source": [
    "seller_setting = ['Duration', 'OpenPrice', 'Merged_endDay', 'currency']\n",
    "\n",
    "X = pd.get_dummies(eBayAuctions_df[seller_setting])\n",
    "y = eBayAuctions_df[outcome]\n",
    "\n",
    "# partition data\n",
    "train_X, valid_X, train_y, valid_y = train_test_split(X, y, test_size=0.4, random_state=1)\n",
    "\n",
    "logit_reg = LogisticRegression(penalty=\"l2\", C=1e42, solver='liblinear')\n",
    "logit_reg.fit(train_X, train_y)\n",
    "\n",
    "logit_reg_proba = logit_reg.predict_proba(valid_X)\n",
    "\n",
    "pd.set_option('display.width', 95)\n",
    "pd.set_option('display.precision',3)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "print('intercept ', logit_reg.intercept_[0])\n",
    "\n",
    "print(pd.DataFrame({'coeff': logit_reg.coef_[0]}, index=X.columns).transpose())\n",
    "print()\n",
    "print('AIC', AIC_score(valid_y, logit_reg.predict(valid_X), df=len(train_X.columns) + 1))\n",
    "pd.reset_option('display.width')\n",
    "pd.reset_option('display.precision')\n",
    "pd.reset_option('display.max_columns')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dvg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
